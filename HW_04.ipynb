{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Vitalina/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pymorphy2\n",
    "from pymorphy2.tagset import OpencorporaTag\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', encoding='utf-8', sep='\\t')\n",
    "target = df_train['target']\n",
    "df_train = df_train.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# морфологический анализатор и опредление англоязычных слов\n",
    "ma = pymorphy2.MorphAnalyzer()\n",
    "latin = OpencorporaTag('LATN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Морфологический кеш\n",
    "parse_results = {}\n",
    "\n",
    "def get_parse_result(word):\n",
    "    # Приведем в нижний регистр\n",
    "    word = word.lower()\n",
    "\n",
    "    # Если слова нет в кеше - разбираем и записываем в кеш\n",
    "    if not (word in parse_results):\n",
    "        pv = ma.parse(word)\n",
    "        for p in pv:\n",
    "            if p.tag.POS in ['ADJF', 'NOUN', 'VERB'] or p.tag == latin:\n",
    "                parse_results[word] = p.normal_form\n",
    "                break\n",
    "\n",
    "    # Если слово не было латиницей или нужной частью речи, вернем None\n",
    "    if not (word in parse_results):\n",
    "        parse_results[word] = None\n",
    "\n",
    "    return parse_results[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем слова\n",
    "def getMeaningfullWords(text):\n",
    "    meaning_words = []\n",
    "\n",
    "    # заменяем тексты в скобках на пустоту\n",
    "    clean_text = re.sub('([\\(]).*?([\\)])', '', text)\n",
    "\n",
    "    # находим слова 3+ символов\n",
    "    all_words = re.findall('[А-ЯЁа-яёA-Za-z]{3,}', clean_text)\n",
    "\n",
    "    for word in all_words:\n",
    "        parse_result = get_parse_result(word)\n",
    "        if parse_result is not None:\n",
    "            meaning_words.append(parse_result)\n",
    "\n",
    "    return meaning_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted_words = [\n",
    "    'Обязанности:', \n",
    "    'Требования:', \n",
    "    'Условия:', \n",
    "    'Что нужно энергичным людям? Интересная и высокооплачиваемая работа в компании единомышленников!',\n",
    "    'Для каждого, кто хочет работать и зарабатывать!Для каждого, кто готов к профессиональному и карьерному росту!Ведущая федеральная розничная сеть магазинов «Пятерочка» приглашает на работу:', \n",
    "    'Должностные обязанности:',\n",
    "    'В крупную, динамично развивающуюся транспортную компанию требуется амбициозный, не боящийся трудностей, целеустремленный и просто позитивный человек, который любит заниматься активными продажами, поиском клиентов, преодолевать трудности и развиваться как профессионал в этой области. Требования:',\n",
    "    'Наши пожелания:',\n",
    "    'Мы ожидаем:',\n",
    "    'ЦЕЛЬ РАБОТЫ:',\n",
    "    'Чем предстоит заниматься:',\n",
    "    'Предоставляем нашим сотрудникам:',\n",
    "    'Ищете работу в перспективной, быстро развивающейся Компании?'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_preproc (df, columns = None):\n",
    "    df = df.drop('id', axis=1)\n",
    "    df['description'] = df['description'].apply(lambda x: re.sub('<.*?>', ' ', x))\n",
    "    \n",
    "    for words in deleted_words:\n",
    "        df['description'] = df['description'].map(lambda x: x.replace(words, ''))\n",
    "\n",
    "    all_text = []\n",
    "    for names in df['name']:\n",
    "        all_text.append(names)\n",
    "    \n",
    "    index = 0\n",
    "    for description in df['description']:\n",
    "        all_text[index]+=' '+description\n",
    "        index += 1\n",
    "    \n",
    "    if columns is None:\n",
    "        count_vect = TfidfVectorizer(tokenizer=getMeaningfullWords, ngram_range=[1,2], min_df=0.01, max_df=0.8, norm='l2', smooth_idf=True, sublinear_tf=True)\n",
    "    else:\n",
    "        count_vect = TfidfVectorizer(tokenizer=getMeaningfullWords, ngram_range=[1,2], vocabulary=columns, norm='l2', smooth_idf=True, sublinear_tf=True)\n",
    "    \n",
    "    matrix_tfidf = count_vect.fit_transform(all_text).toarray()\n",
    "    \n",
    "    df = pd.DataFrame(matrix_tfidf, columns=count_vect.get_feature_names())\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_preproc(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CorrKoef = df_train.corr()\n",
    "# FieldDrop = [i for i in CorrKoef if CorrKoef[i].isnull().drop_duplicates().values[0]]\n",
    "# CorField = []\n",
    "# for i in CorrKoef:\n",
    "#     for j in CorrKoef.index[CorrKoef[i] > 0.9]:\n",
    "#         if i != j and j not in CorField and i not in CorField:\n",
    "#             CorField.append(j)\n",
    "#             print(\"{}-->{}: r^2={}\".format(i, j, CorrKoef[i][CorrKoef.index==j].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr = Pipeline([StandardScaler(), LogisticRegression()])\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9894379643257674"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_predict = lr.predict(X_test)\n",
    "lr_predict_proba = lr.predict_proba(X_test) \n",
    "roc_auc_score(y_test, lr_predict_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42, n_estimators=100, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923233738710031"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predict = rf.predict(X_test)\n",
    "rf_predict_proba = rf.predict_proba(X_test) \n",
    "roc_auc_score(y_test, rf_predict_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv', encoding='utf-8', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_preproc(df_test, df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict = rf.predict(df_test)\n",
    "model_for_file = pd.DataFrame(columns=['id', 'target'])\n",
    "\n",
    "model_for_file['id'] = df_id\n",
    "model_for_file['target'] = model_predict\n",
    "model_for_file.to_csv('predict.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
